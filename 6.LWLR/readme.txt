用预测数据来预测鲍鱼的年龄
由于数据量实在太大，而局部加权线性回归计算量很大，所以实际玩数据时只选取了200个数据
最后得出的预测值也不知道和实际值相差多少才算好的预测（需要用到均方误差？不知道啊，看完本书再研究）
打算用局部加权线性回归来玩，关于岭回归，lasso方法，逐步回归，向前回归，向后回归的方法看完本书之后再研究
后续主要的研究点：岭回归的编程与画图，怎么用岭回归缩减参数，pythonskt包中的lasso方法，逐步回归的编程与画图，向前向后回归检验均方误差显著性检验的原理，向前向后回归的编程。貌似lasso方法编程很麻烦，所以只要求到skt里面找轮子即可、

思路整理：
考虑有常量参数b的局部加权线性回归模型，运用交叉验证来选取令人满意的最佳的核
首先建立解析器提取训练数据，输出一个list
然后建立一个选取器，输入list，输出标准化的训练数据矩阵，标签矩阵以及测试数据矩阵和标签矩阵
然后建立LWLR器，对每一个数据，输出预测系数
然后建立交叉验证器，对每一个核函数的k值，对测试数据分别调用LWLR器，并记录测试误差。
然后建立作图器，通过绘制测试误差随着logk变化的情况（一般是一个开口向上的抛物线）来选取最佳的k值

写代码时觉察到的决策树算法的缺点和改进点：
1.直接计算行列式的方式来计算标准线性回归
2.计算相关系数来查看预测结果集和实际结果集的不同
3.当数据很多时，计算量太大了。
4.写代码的时候碰到2个问题，一个是核函数写错了导致k为一定值时核函数返回0，最后导致方差阵为0，无解；第二个是测试数据没有用训练数据的平均值和方差标准化

学到的python代码：
1.对于一个list，可以运用numpy的random.shuffle()函数对其中的元素进行混洗
shuffle() 方法将序列的所有元素随机排序。
2.对于mat形式的数据，mean(traininglist,0)可以求平均值，var(traininglist,0)可以求方差
mat的减法是矩阵内元素的减法，mat的除法是矩阵内元素的除法，mat的乘法是矩阵乘法，
3.eye(10)创建一个10x10的单位对角阵；linalg.det(mtm)求行列式；mtm.I求逆
4.fig=plt.figure()创建一个画板；ax=fig.add_subplot(111)增加画图区；ax=plot(karr,error)画折线图
plt.show()图形展示
5.mat数据不能用testinglist[0][0]这个来取里面的值



